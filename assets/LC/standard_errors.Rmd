---
title: "Standard Errors"
author: "Albert Y. Kim"
date: "Wed Nov 30, 2016"
output:
  html_document:
    toc: true
    toc_float: true
    collapsed: false
    smooth_scroll: false
---

Let's revisit the OkCupid profile data. Run the following in your console:

```{r, echo=TRUE, message=FALSE}
library(mosaic)
library(dplyr)
library(ggplot2)

library(okcupiddata)
data(profiles)

# Remove individuals with no listed height
profiles <- profiles %>% 
  filter(!is.na(height))
```

We take many, many, many samples of size 5 and then take the sample mean:

```{r, echo=TRUE, message=FALSE, eval=TRUE, cache=TRUE}
n <- 5
samples_5 <- do(10000) * 
  mean(resample(profiles$height, size=n, replace=TRUE))
samples_5 <- samples_5 %>% 
  as_data_frame() 
```

We take many, many, many samples of size 50 and then take the sample mean:

```{r, echo=TRUE, message=FALSE, eval=TRUE, cache=TRUE}
n <- 50
samples_50 <- do(10000) * 
  mean(resample(profiles$height, size=n, replace=TRUE))
samples_50 <- samples_50 %>% 
  as_data_frame() 
```


## Learning Checks

1. Explicity compute the **standard error** when taking samples of size `n=5` and `n=50`. 
2. Discuss with your peers **why** they matter in any study that involves some kind of sampling.


#### LC1

**In General**: The standard error is the standard deviation of the point estimate. In this case, it is the value that quantifies how much the sample means vary by.

**In Our Case**: If we take a sample of 5 OkCupid users and compute the (sample) mean height, are we going to get the same value each time? No. The SE measures this sample mean varies.

**Mathematically**: You can derive the standard error mathematically, but this is for a more advanced class in Probability/Statistics. See Advanced section below.

**Computationally**: It is the standard deviation of our 10000 sample means:

```{r, echo=TRUE, message=FALSE, eval=TRUE}
samples_5 %>% 
  summarise(SE = sd(mean))
samples_50 %>% 
  summarise(SE = sd(mean))
```


**Results**:

1. The SE with `n=50` is smaller i.e.
1. The sample mean $\overline{x}$ are less variable when `n=50`
1. The sample mean $\overline{x}$ is more precise when `n=50`
1. **Our estimates are on average better when `n=50`**


**Visualization**: Recall, the sampling distribution is the distribution of the point estimate. We see that for `n=50`

* the distribution is narrower i.e. 
* it has a smaller standard deviation i.e.
* the standard error is smaller
* **Our estimates are on average better when `n=50`. Bigger sample size is better.**

```{r, echo=FALSE, message=FALSE, warning=FALSE, eval=TRUE, fig.height=9/2, fig.width=16/2}
samples_5 <- samples_5 %>% 
  mutate(n="n=5")

samples_50 <- samples_50 %>% 
  mutate(n="n=50")

samples <- bind_rows(
  samples_5, samples_50
)

ggplot(samples, aes(x=mean)) +
  facet_wrap(~n) + 
  geom_histogram(binwidth = 1) +
  xlim(c(40,90))
```


#### LC2

From sample to sample, your point estimate, in this case the sample mean, will
vary! i.e. there is **uncertainty**. How much uncertainty? The SE quantifies
this!


#### Advanced

If you're curious, the mathematically/probabilistically derived formula for the Standard Error is $\mbox{SE}_{\overline{x}} = \frac{\sigma}{\sqrt{n}}$ where 

* $\sigma$ is the **population standard deviation**: the true standard deviation of the 60K heights (and not the standard deviation of the 10000 many, many, many sample means)
* $n$ is the sample size (and not the many, many, many number of times `n`)

Note how $n$ is in the denominator. So

* As $n \longrightarrow \infty$, we have $\mbox{SE}_{\overline{x}} \longrightarrow 0$ i.e. 
* As $n \longrightarrow \infty$, there is no uncertainty in our estimate $\overline{x}$ of $\mu$, we know the answer exactly!

In our case since $\sigma$ = `sd(profiles$height)` = `r sd(profiles$height) %>%
round(3)`, we have for

* `n=5`: SE = $\frac{3.995}{\sqrt{5}} = 1.787$
* `n=50`: SE = $\frac{3.995}{\sqrt{50}} = 0.564$

Note these are pretty close to the computationally computed values above. Why is
$\mbox{SE}_{\overline{x}} = \frac{\sigma}{\sqrt{n}}$? You need the tools from
Probability MATH 310 to show this.