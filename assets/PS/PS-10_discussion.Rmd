
---
title: "Problem Set 10"
author: "WRITE YOUR NAME HERE"
date: "Due Monday, November 28, 2016 at 5pm"
output:
  html_document
---



```{r, message=FALSE, echo=TRUE, warning=FALSE}
library(ggplot2)
library(dplyr)
library(mosaic)
library(readr)
library(knitr)
set.seed(76)
```


## Question 1:

Answer the question from Question 3 from the midterm "The Dude Rolling Die": is 
he full of BS or can he actually correctly predict die rolls? Base your answer
on the p-value.

For this question, since there are only 7 possible outcomes (# correct out of 6
guesses), use a `geom_bar()` instead of a `geom_histogram()` to show your
results.

#### Set Up

* $H_0:$ the dude is BS
* $H_A:$ the dude can actually tell

* Now let's suppose $H_0$ is true, i.e. he's just BS'ing. Then there is a 1 in 6
chance he is correct.
* The **test statistic** is the number out of 6 die rolls he got correct. The
**observed test statistic** is 3 out of 6 right.
* Do this many, many, many times to construct the **null distribution** of the
test statistic.

```{r, message=FALSE, echo=TRUE, warning=FALSE, fig.width=16/2, fig.height=9/2, cache=TRUE}
die <- c(1, 0, 0, 0, 0, 0)
simulations <- do(10000) * resample(die, 6)
simulations <- simulations %>% 
  as_data_frame() %>% 
  mutate(correct=V1+V2+V3+V4+V5+V6)
```

```{r, message=FALSE, echo=TRUE, warning=FALSE, fig.width=16/2, fig.height=9/2}
ggplot(simulations, aes(x=correct)) +
  geom_bar() +
  geom_vline(xintercept=3, col="red")
```

#### p-Value

The p-value is the proportion of time he gets 3 or more right. Since

```{r, message=FALSE, echo=TRUE, warning=FALSE, fig.width=16/2, fig.height=9/2}
simulations %>% 
  mutate(three_or_more = correct >= 3) %>% 
  summarise(total=sum(three_or_more))
```

the p-value is

$$
\frac{553+1}{10000+1} = 0.055 = 5.5\mbox{%}
$$

Recall we add 1 to the numerator and denominator to account for the observed test statistic.

#### Conclusion:

I would say this person can actually guess right. Maybe he's got die he can
cheat with?



## Question 2:

#### a) 

Let's consider the hiring data in `hiring.csv`. Let's say we are only looking
for mild evidence that women got lower `hireable` scores than men.

1. Create an appropriate exploratory data analysis visualization.
1. Perform an hypothesis test of
    + $H_0:$ men and women got the on average the same `hireable` score vs
    + $H_A:$ you choose! state your choice below
1. State the conclusion of the test both
    + in statistical language
    + in terms of the data's context.

**Exploratory Data Analysis**

There are many ways to visualize data when you have two-sample, but I like boxplots,
because you can make comparisons with a single line. 

```{r, message=FALSE, echo=TRUE, warning=FALSE, fig.width=16/2, fig.height=9/2}
# Copy the code that loads hiring.csv into RStudio here:
hiring <- read_csv("hiring.csv")

# Do your exploratory data analysis here:
ggplot(hiring, aes(x=applicant_gender, y=hireable)) + 
  geom_boxplot()

# Observed Difference
mean(hireable~applicant_gender, data=hiring)
mean(hireable~applicant_gender, data=hiring) %>% diff()
```

Looking at the graph, men got almost an entire point higher **median** evaluation
score. i.e. male - female = 0.85594.


**Hypothesis Test**

We'll do the following hypothesis test:

* $H_0:$ men and women got the on average the same `hireable` score
* $H_A:$ men get higher scores

Or stated statistically

* $H_0:$ $\mu_{men} - \mu_{women} = 0$
* $H_A:$ $\mu_{men} - \mu_{women} > 0$

Hence in this case **more extreme** means **more positive** i.e. men get rated higher. i.e. to the right.

```{r, message=FALSE, echo=TRUE, warning=FALSE, fig.width=16/2, fig.height=9/2}
# Perform your hypothesis test
obs_diff <- mean(hireable~applicant_gender, data=hiring) %>% diff()

simulations <- do(10000) * mean(hireable~shuffle(applicant_gender), data=hiring)
simulations <- simulations %>% 
  as_data_frame() %>% 
  mutate(diff=male-female)

ggplot(simulations, aes(x=diff)) + 
  geom_histogram() + 
  geom_vline(xintercept=obs_diff, col="red") +
  labs(x="Applicant Gender")
```


**Conclusion**

**You don't need a PhD in statistics**, to see here the difference is 
ultra-significant: getting a difference of 0.85594 in favor of men is **not even
plausible** if men and women applicants were rated equally. The p-value is
essentially 0.

If you still want to compute it, it's

```{r, message=FALSE, echo=TRUE, warning=FALSE, fig.width=16/2, fig.height=9/2}
simulations %>% 
  mutate(more_extreme_right = diff >= obs_diff) %>% 
  summarise(count = sum(more_extreme_right))
```

$$
\frac{0+1}{10000+1} \approx 0.0001 = 0.01\mbox{%}
$$



#### b) 

Who penalized women applicants more on average? The male evaluators or the
female evaluators? Do not perform an exhaustive hypothesis test, but rather

1. Generate an appropriate exploratory data analysis visualization AND
1. Summarize the data in an appropriate table of values


**Visualization**

A lot of you did this I imagine:

1. Separate out the females
1. Compare the hireability scores and observed that women rated women higher.

```{r, message=FALSE, echo=TRUE, warning=FALSE, fig.width=16/2, fig.height=9/2}
hiring_female <- hiring %>%
  filter(applicant_gender == "female")
ggplot(data=hiring_female, aes(x=evaluator_gender, y=hireable)) +
  geom_boxplot() +
  labs(title="Only Female Applicants", x="Evaluator Gender")
```

Are we done? **No**. Women are more generous evaluators to begin with! That's
the appropriate baseline! We need to compare women evaluators scores for women
**relative** to their already higher scores.

```{r, message=FALSE, echo=TRUE, warning=FALSE, eval=FALSE, fig.width=16/2, fig.height=9/2}
ggplot(data=hiring, aes(x=applicant_gender, y=hireable)) +
  geom_boxplot() +
  facet_wrap(~evaluator_gender) +
  labs(x="Applicant Gender", title="All Applicants")
```
```{r, message=FALSE, echo=FALSE, warning=FALSE, eval=TRUE, fig.width=16/2, fig.height=9/2}
hiring %>% 
  mutate(evaluator_gender = ifelse(evaluator_gender=="female", "Female Evaluator", "Male Evaluator")) %>% 
  ggplot(aes(x=applicant_gender, y=hireable)) +
  geom_boxplot() +
  facet_wrap(~evaluator_gender) +
  labs(x="Applicant Gender", title="All Applicants")
```


**Table**

```{r, message=FALSE, echo=TRUE, warning=FALSE, eval=FALSE, fig.width=16/2, fig.height=9/2}
hiring %>%
  group_by(evaluator_gender, applicant_gender) %>%
  summarise(hireable=mean(hireable)) %>% 
  mutate(hireable=round(hireable, 2))
```
```{r, message=FALSE, echo=FALSE, warning=FALSE, fig.width=16/2, fig.height=9/2}
hiring %>%
  group_by(evaluator_gender, applicant_gender) %>%
  summarise(hireable=mean(hireable)) %>% 
  mutate(hireable=round(hireable, 2)) %>% 
  rename(`avg hireable` = hireable) %>% 
  kable()
```

* Female evaluators rated men 3.92 - 2.84 = 1.08 points higher on average
* Male evaluators rated men 3.74 - 2.96 = 0.78 points higher on average

So 

1. **Moral of the Story**: Women were in fact harsher.
2. **Question**: Is the difference between 0.78 and 1.08 significant? Now you need to use statistics.



#### Where did this data come from?

* A real study done by Corinne Moss-Racusin (Yale Dept of Psychology) et al. in 2012, published in the  
<a href = "https://rudeboybert.github.io/MATH116/assets/PS/raw_data/PNAS/PNAS-2012-Moss-Racusin-16474-9.pdf" target = "_blank">Proceedings of the National Academy of Sciences</a>.
* A summary of this article can be found in [Scientific American](https://blogs.scientificamerican.com/unofficial-prognosis/study-shows-gender-bias-in-science-is-real-heres-why-it-matters/).

Another example, but not randomly assigning "gender", but "race":

* [Professors Are Prejudiced, Too](http://www.nytimes.com/2014/05/11/opinion/sunday/professors-are-prejudiced-too.html)
